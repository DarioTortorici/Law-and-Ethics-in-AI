\section{Artificial Intelligence and Civil Liability}

The ability of AI systems to perform tasks autonomously also gives them the potential to cause harm to persons and/or property. Such an eventuality is covered by tort law, which deals with establishing whether the cost of an accident should shift from the victim to another person who is to be held liable. Tort law is mostly regulated by national legal systems, but sometimes the EU legislator takes action by harmonizing certain liability rules among Member States in order to ensure the functioning of the internal market. For instance, in Italy Article 2043 of the Civil Code states that any intentional or negligent act that causes wrongful harm to another obliges the offender to compensate the damage. Such general tort law rule establishes a fault-based liability, according to which the tortfeasor must have acted at least negligently to be held liable and the burden of proof of such conduct rests on the injured person.

\subsection{The responsibility gap}

The features of modern AI pose serious challenges to the validity of traditional liability rules. In fact, the autonomy and unpredictability of AI’s behavior led many scholars to elaborate the so-called ‘responsibility gap doctrine’, according to which the lack of human control over the algorithm could make no longer suitable to hold the manufacturer and/or the user of the product liable. Following this approach, unlike traditional engineering designs, the actual functioning of a software agent is not always predictable, and predictability is a central element in today’s liability systems. The gap in the protection of injured parties actually appears also on a different regulatory level. While tort law takes an ex-post view of individuals’ protection by ensuring them compensation once the damage effectively occurred, the law is also concerned with establishing ex-ante safety rules and standards to be respected by manufacturers willing to put a product into circulation, in order to ensure consumers an adequate level of protection. Nevertheless, although they are linked to each other, tort law (and product liability in particular) and safety rules are to be treated separately due to their different functions and scope of application.

\subsection{Product Liability Directive (PDL)}

The absence of a safety legislation on AI led the European Commission to adopt the ‘\hyperref[sec:AIAct]{AI Act}’ proposal in 2021, which appears to be a horizontal regulation since it deals with ensuring the safety of ‘high-risk’ AI systems irrespective of whether they are placed on the market independently or as components of other products. Once entered into force, the \hyperref[sec:AIAct]{AI Act} will be an important step towards a uniform regulation of AI in the EU. At the same time, more recently the Commission has presented two directive proposals on civil liability which would affect the victim protection before national courts.

\subsection{Civil liability and smart products}

The autonomous behavior of AI systems will make it extremely likely that damages will be mostly caused by a defective functioning of such products. Firstly, it is not clear whether the PLD’s scope of application covers AI systems. There's still a debate in the literature on whether to consider software as a product or a service. The ongoing legal uncertainty surrounding this aspect puts in serious danger the possibility for the victim to invoke the protection provided by the PLD when it comes to harmful AI systems.

The second and most important issue deals with the burden of proof set out in the Directive. Even though the manufacturer is deemed to be strictly liable, Article 4 of the PLD requires the plaintiff to prove the damage, the defect, and the causal link between them. The complexity characterizing modern AI systems can make such evidence difficult to provide for the consumer. On the other hand, the definition of ‘defective product’ provided by Article 6 of the PLD shows a possible wide interpretation of the notion, which is not necessarily linked to the demonstration of a technical malfunction of the product, but it deals with ‘the safety which a person is entitled to expect,’ taking all circumstances into account.

\subsection{The upcoming EU legislation}

The European Union has been concerned about the issue of filling the AI responsibility gap. The European Commission adopted two directive proposals on 28th September 2022 concerning civil liability. The first one, also known as ‘AI Liability Directive’ (AILD), aims at adapting non-contractual civil liability rules to artificial intelligence; the second one is a new Product Liability Directive, replacing the current PLD.

The AILD refers to non-contractual fault-based civil law claims for damages, in cases where the damage caused by an AI system occurs. Its purpose is to alleviate the plaintiff’s burden of proving fault and causation. In fact, the victim is entitled to ask a national court to order a provider to disclose relevant evidence about a specific high-risk AI system that is suspected of having caused damage. The AILD aims at realizing a strong coordination between safety legislation and tort law, by means of a fault liability regime for non-compliance with the \hyperref[sec:AIAct]{AI Act}.

The new PLD aims at remedying the problems seen above with respect to the challenges posed by the digital age to manufacturer’s liability. In this regard, the novelties brought by the proposal encompass not only AI, but the digital innovation in general. Article 4 of the new PLD explicitly includes digital manufacturing files and software in the definition of ‘product,’ thus putting an end to the debate about the applicability of the Directive to AI systems. On the other hand, according to Article 10(2), the defendant cannot escape liability providing the later-defect defense where the defectiveness of the product is due to the updates and upgrades of the software, provided that it is within the manufacturer’s control.

The new PLD proposal establishes presumptions to alleviate the burden of proof on the injured person. In fact, upon request of the claimant, Article 8 enables the court to order the defendant to disclose relevant evidence that is at its disposal, and, under Article 9, the defectiveness of the product shall be presumed where the defendant has failed to comply with such an obligation to disclose.


