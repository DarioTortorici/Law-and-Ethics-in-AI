\section{Research Pathways on AI and Criminal Law}

Four distinct research pathways are identified concerning artificial intelligence (AI) and criminal law:

\begin{enumerate}
    \item AI and law enforcement activities.
    \item AI and judicial decisions (robot-judge).
    \item AI and crime-risk assessment.
    \item AI and criminal liability.
\end{enumerate}

This piece will focus solely on AI's implications for criminal liability, specifically addressing the question of responsibility when AIs cause harm.

\section{Purposes of Criminal Law: Theories of Punishment}

Three fundamental theories of punishment exist:

\begin{enumerate}
    \item Retribution: This theory seeks revenge or retribution for harm caused by the perpetrator to victims and society.
    \item General Prevention (Deterrence): Punishment aims to deter others from committing crimes.
    \item Special Prevention: Focuses on deterring the perpetrator from committing further crimes, often involving re-educative purposes such as rehabilitation.
\end{enumerate}

\section{Criteria for Legislating Crimes}

To define a crime, lawmakers consider several principles:

\begin{enumerate}
    \item Harm Principle: Does the conduct to be criminalized damage a legal interest, such as life?
    \item Legality Principle: Can the conduct be described clearly and precisely in codified terms, proven 'beyond any reasonable doubt'?
    \item Culpability Principle: Can the conduct be committed intentionally, recklessly, or negligently? Can the perpetrator control the referenced phenomenon?
    \item Subsidiarity Principle: Is criminal law the best means to protect the legal interest at hand? Is it necessary and proportionate, considering its impact on individual rights and liberties, or can other legal sectors address the issue effectively (e.g., torts or administrative sanctions)?
\end{enumerate}

\section{Thesis: AIs as Legal Subjects}

Professor Gabriel Hallevy, citing Professor Lawrence B. Solum, asserted that there exists a fear among people that AIs "are not considered to be subject to the law, specifically to criminal law." This fear parallels historical concerns regarding corporations and their capacity to commit crimes. However, Hallevy contends that "because corporations are legal entities subject to criminal and corporate law, that kind of fear has been significantly reduced." He presents three models of criminal liability involving AIs:

\subsection{Perpetration-through-another Model}
In this model, AI entities lack human attributes and are viewed as innocent agents utilized by the actual perpetrator (principal) - the programmer or user. This aligns with the paradigm of perpetration-by-means, focusing on individuals not actively involved in the criminal act, such as children or mentally incapacitated individuals unwittingly manipulated into executing a criminal plan.

\subsection{Natural-Probable-Consequence Model}
Here, AI systems are considered objects, holding the programmers and/or users accountable if an offense is committed through AI as a natural and probable consequence of their intentional or negligent actions.

\subsection{Direct Liability Model}
This model does not assume dependency of the AI entity on a specific programmer or user. It considers the AI entity as a legal person, attributing the actus reus easily to AI entities. However, attributing the internal elements of offenses to AI entities poses a legal challenge. While acknowledging that AI lacks feelings that humans possess, Hallevy argues that most offenses do not require these feelings. Corporations, historically treated as criminal law subjects since the Langforth Bridge case in 1635, lead to the question: "Why should AI entities be different from corporations?" As AI entities increasingly participate in human activities, similar to corporations, Hallevy questions the differentiation in their treatment under criminal law.

\subsection{Antithesis: AIs as Mere Instruments of Crime}

\subsubsection{Is AI Actually Intelligent?}

Contrary to popular belief, artificial intelligences (AIs) are not inherently intelligent. Two primary approaches are associated with AI: model-based and machine learning (ML)-based AI.

\textbf{Model-based AI:} In this approach, the system emulates the behaviors of domain experts. The programmer, usually a computer science expert, collaborates with field experts (e.g., medicine) to define a knowledge representation about a specific phenomenon (e.g., myocardial infarction). This model is integrated into the system to enable analysis and treatment of the phenomenon. There are two types of model-based AI:

\begin{enumerate}
    \item Systems based on if-then rules, where the system formulates conclusions based on given premises to address posed questions by the programmer.
    \item Systems based on 'trees' organizing knowledge by referencing an ideal tree's shape, branching into data classification alternatives to produce an output.
\end{enumerate}

\textbf{ML-based AI:} This approach constructs a phenomenon's model from various data sources like the internet, city sensors, and smartwatch sensors. It utilizes statistics and probability theory to form complex knowledge representations through different learning methods and computational models for data analysis:

\begin{enumerate}
    \item \textit{Supervised learning:} The programmer defines training sets including data related to a phenomenon and creates a computational model trained to understand the information in the sets. The system learns and adjusts based on the comparison between expected and actual outcomes.
    \item \textit{Unsupervised learning:} No expected results or error-reports are provided, commonly used for clustering similar elements together based on analogies or connections.
    \item \textit{Reinforcement learning:} Operates through a reward-punishment mechanism, where feedback messages guide the system. Success or failure is evaluated after multiple decisions, and a credit assignment procedure identifies successful decisions.
\end{enumerate}

Unlike model-based AI, ML focuses on data collection and their inclusion within training sets to train computational models like artificial neural networks (ANNs). ANNs are inspired by the functioning of biological neural networks (BNNs), presenting similarities in their highly interconnected computational tools and the impact of input signals affected by adaptive coefficients.

\subsubsection{The Substantial Legal Difference between Corporations and AI Systems}

The argument suggesting there is "no substantial legal difference between the idea of criminal liability imposed on corporations and on AI entities" is unfounded, as there exists a significant legal distinction between the two. 

In Hallevy's third model, where no dependence between the AI entity and a human being (programmer or user) is assumed, the liability of corporations differs significantly. For instance:
- In the United States, corporations are held accountable for acts committed by their agents within the scope of their employment, provided that there is a purpose to benefit the corporation.
- This principle aligns with 'vicarious liability,' attributing the offense, both actus reus and mens rea, committed by a human representing the corporation, automatically to the corporation itself.
- In Italy, Law no. 231 of 2001 holds corporations responsible for a crime under specific conditions:
    - A natural person linked to the entity commits one of the listed offenses.
    - There is an objective link between the corporation and the crime committed in the interest or for the benefit of the corporation.
    - Distinctions are made based on the perpetrator of the crime, senior management or subordinate employees, determining the corporation's liability.

For offenses committed by senior managers:
- The corporation is not liable if it can prove the adoption and effective enforcement of a compliance program aimed at preventing such crimes. This includes delegation to an overseeing body within the corporation, endowed with adequate initiative and control powers.

For offenses committed by subordinate employees:
- The corporation's liability arises only if noncompliance with management or supervisory obligations enabled the offense. However, compliance with a previously adopted and efficiently implemented compliance program can absolve the corporation of liability.

The effectiveness of the compliance program mandates regular assessments, amendments, and the existence of a disciplinary system to sanction noncompliance.

