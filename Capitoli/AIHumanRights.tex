\section{Introduction}
AI is not just another technology. In this chapter, we explore how certain old, established rights can be adapted to grapple with the novel challenges posed by AI. Additionally, we consider four 'emerging' rights that warrant careful consideration.

\section{AI Characteristics}
For AI to achieve its full potential and optimize its performance, it necessitates a conducive context and an environment built around it. For example, our cities are evolving into smart urban centers, much like the modification of homes for increasingly efficient smart home automation. Essentially, we are adapting the environments we inhabit (and perhaps ourselves) to be 'AI-friendly'. Some authors refer to an "envelope" being constructed around AI, and consequently, around ourselves, encapsulating the transformative capacity of AI. It is imperative that the pervasive and transformative potential of AI serves the majority of humanity rather than becoming a tool for exploitation by a few to the detriment of many.

\section{Old Rights and Principles}
\subsection{Informed Consent}
Certain traditional rights can be adapted to the new challenges posed by AI. One initial old right that can be adapted is informed consent. Faced with AI systems that we can no longer distinguish from humans, it is important to recognize the right to know whether we are interacting with a person or a machine. This right, viewed as a new version of informed consent, is already acknowledged in the European proposal for AI regulation (\hyperref[sec:AIAct]{AI Act}, art 52). Additionally, at a national level, France amended the “Loi Bioéthique” in August 2021, stating that a doctor who decides to use AI for their profession “must ensure that the person concerned has been informed and is informed of the interpretation that results from it”. It is also important to have insights into the reasons that led the machine to generate a certain outcome. This aspect is complicated by the phenomenon known as the ‘black box’. In essence, the black box poses a risk to the acknowledgment and legitimacy of activities that employ AI systems. The second problem concerns rectifying errors that the system might make, given the extreme difficulty, and sometimes impossibility, of pinpointing where the machine went wrong. In this regard as well, the European Union’s proposed AI regulation introduces a right that can be seen as a new iteration of the principle of informed consent.

\subsection{Non-discrimination}
A second established principle that can be adapted for the use of AI is non-discrimination. It is well-known that the outputs generated by AI can be biased, erroneous, imprecise, and lead to discriminatory effects. Experts are actively working to address the discriminatory effects of AI, yet the problem remains unresolved. 'Cleaning' the datasets used, by incorporating accurate and comprehensive information, is a necessary step toward achieving accurate outputs, but it does not completely solve the problem. Even with accurate information, the statistical-probabilistic logic that AI operates on can arrive at conclusions that discriminate, for instance, based on ethnicity, race, or gender. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used” (Article 10.3). To address this challenge, tackling the first of the 'new rights' can be useful: the right to “Human in the Loop”. That is, the right to decisions that are not solely made by an artificial system. In essence, it entails the right to be recipients of decisions subject to significant human oversight, to mitigate potential errors and discriminatory outcomes from machines.

\section{New Rights}

\subsection{Human in the Loop and the Right to the Hero}
It is recommended that decisions made with the assistance of AI are always supervised and controlled by a person who takes responsibility for the decision itself. In Europe, this right is already partially recognized under the General Data Protection Regulation in Art. 22. Despite this commendable effort, however, there remains a concrete risk that the principle of human oversight may remain merely a formal and fictitious element. How many public administration officials, for instance, possess the computer skills necessary to understand and accurately interpret the outputs of a system whose inner workings even their designers are ignorant of? And how many will take on the burden of justifying a decision that deviates from what the machine dictates? The risk, as Antoine Garapon puts it, is the “\textbf{effet moutonnier}”, a phenomenon of standardization and de-responsibilization stemming from the fact that the decision is actually “captured” by the algorithm, rendering the principle of human oversight merely superficial, proclaimed but not effectively and practically applied. To exercise it, in fact, would require a professional who not only possesses specific computer science expertise but is also strongly motivated to counter what they deem incorrect, personally assuming the responsibility and corresponding risk; it would require – one might say – a true hero. In this sense, paradoxically, one could speak in terms of a ‘right to the hero’ or a ‘right to heroism’.

\subsection{The Right to Discontinuity}
The second of the new rights that could be proposed here is connected to the statistical-probabilistic approach with which AI operates. In particular, the profiling to which all of us are subjected is based on what we could call our ‘historical self’, consisting of preferences, orientations, and decisions as we have expressed them in the past. The risk, therefore, is to become trapped in a past that is impervious to potential new interests, curiosities, and changes. The result of this profiling is placing them within a comfort zone, an echo chamber whose effect, in the absence of true confrontation, is a progressive and radical polarization of their own ideas. From this perspective, to preserve a minimum of curiosity, doubt, and a desire for change (or we could say, authentic freedom), one could invoke a kind of new right to discontinuity or inconsistency; a right to "step out of the bubble".

\subsection{The Right to a Human Environment}
A third new right is linked to the mentioned pervasive and transformative scope of AI. To optimize the functioning of the most advanced systems, it is necessary to build around them an environment suited to make them operate most efficiently. This trend of constructing "AI-friendly" environments is increasingly spreading, resulting in what could be described as a Midas touch effect, where things that come into contact with technology are transformed. In this regard, attention must be paid to ensure that this type of location does not produce the effect of excluding humans from the environments they have always lived in; otherwise, we would risk living in a world tailored to AI, rather than tailored to humans. For this reason, the envelope must be limited to environments where we want to prioritize the performance and effectiveness of AI.

\subsection{The Right to AI and Private Powers}
With the AI advent, private powers come to perform essential functions, functions of a public nature, such as education, healthcare, and justice. The limitation of powers, including those of private entities that dominate the AI world, and the guarantee of rights are crucial. AI also offers enormous potential to enhance our existence. This position could be linked to what was already established in 1948 by the Universal Declaration of Human Rights, which states that "Everyone has the right... to share in scientific advancement and its benefits."
