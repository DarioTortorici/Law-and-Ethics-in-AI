\section{AI in the GDPR}

The use of AI and algorithms in data processing has drawn considerable attention in data protection laws. Directive 95/46/EC established the right for individuals to avoid decisions solely based on automated data processing, particularly those significantly impacting them, and mandated disclosure of the logic behind such processes.
\newline
The GDPR reinforced these principles, ensuring individuals aren't subject to decisions made solely by AI. If such decisions have legal implications or significantly impact individuals, they have the right to human intervention, expression of their views, and the ability to contest the decision. Additionally, controllers must disclose the logic behind AI-driven decisions, posing a challenge when algorithms function as black boxes.
\newline
The Art. 29 Data Protection Working Party addressed this, emphasizing "accountability" as the GDPR's core theme for data controllers and highlighting "transparency" as fundamental to all personal data processing.
\newline
Key aspects of the European regulations include:

\begin{itemize}
    \item \textbf{Transparency}: It's not just a processing principle but a rightful demand for individuals. Controllers must ensure accessible, understandable information regarding data processing, using clear language (Recital 39 GDPR).
    
    \item \textbf{Accuracy}: Tied closely to transparency, ensuring provided information allows individuals to comprehend processing methods and consequences.
    
    \item \textbf{Accountability}: Art. 24 GDPR elevates the responsibility of data controllers from checklist compliance to case-specific assessment. This isn't limited to solely automated evaluations but extends to any automated profiling using AI, machine learning, or similar technologies impacting individuals, even with human intervention in result assessment.
\end{itemize}

\section{The prohibition of automated decisions}
The new European Regulation, while not significantly innovating from Directive 95/46/EC Article 15, introduces critical distinctions. Art. 4, pt. 4 of the GDPR defines "\textbf{profiling}." Profiling hinges not merely on classifying individuals but on the purpose behind the classification. This definition retains some ambiguity, especially considering companies regularly process statistical data for business decisions.
\newline
Another crucial term is "\textbf{legal effects}" under Art. 22, para. 1, GDPR, implying decisions producing legal consequences or significantly affecting individuals. The term "similarly" narrows the provision, demanding a profound impact akin to a legal effect. Art. 29 Working Partyâ€™s guidelines clarify that the threshold for significance should resemble that of a decision affecting rights.
\newline
However, interpreting terms like "solely" remains unclear in the context of advanced AI technologies blurring the line between fully automated and human-involved processing.
\newline
Despite the general prohibition on automated decisions, Art. 22, para. 2, provides exceptions:

\begin{itemize}
    \item Necessary for contract performance.
    \item Authorized by applicable law ensuring data subject rights.
    \item Based on explicit consent of the data subject.
\end{itemize}

Art. 22, para. 4, permits automated processing of special data categories under certain conditions, primarily reliant on explicit consent or reasons of substantial public interest, respecting fundamental rights.
\newline
Obtaining informed consent for inherently non-transparent processes (like "black-box" algorithms) poses significant challenges, particularly in scenarios involving sensitive health data.
\newline
Safeguarding data subject rights and freedoms is crucial. Art. 22, para. 3, ensures individuals have the right to human intervention, expressing their views, and contesting decisions related to contract-based or consent-based automated decisions.

\section{A right to explanation or only a right to be informed?}
AI's "original sin" lies in the opacity surrounding their functionality and reasoning, making algorithms not just opaque but also prone to evolving unpredictably over time.
\newline
The term "black boxes" elucidates this phenomenon. The "organizational black box" highlights algorithms often managed by profit-driven entities with minimal transparency obligations. Then, there are "technical black boxes" tied to AI's intrinsic decision-making complexity (e.g., "neural networks" modeled on the human brain). Finally, the "legal black boxes" relate to intellectual property rights impacting technology management and transparency.
\newline
This inherent lack of transparency significantly impacts accountability. Transparency stands as a foundational principle of GDPR. Personal data processing must be made intelligible for data subjects, chiefly through the information notice. Unlike Directive 95/46/EC, GDPR necessitates specific information to ensure fair and transparent processing:

\begin{enumerate}
    \item Explanation of the decision-making algorithm's existence by the data controller.
    \item Informing the data subject of the logic used.
    \item Opening up the algorithm to provide "meaningful information about the significance and envisaged consequences of such processing for the data subject" (Art. 13, para. 2, letter f, GDPR).
\end{enumerate}

The right to explanation may vary in interpretation. Additionally, explanations may occur at different stages: an \textbf{ex ante} explanation happening before the automated decision-making process is implemented (focused on system functionality), and an \textbf{ex post} explanation occurring after implementation.
\newline 
Scholars' opinions diverge on GDPR's stance regarding the right to explanation. Some critique GDPR for lacking an explicit right to explanation despite the right to be informed.
\newline
Others propose an extensive interpretation of Articles 15 and 22 to fulfill the transparency principle, advocating for a legibility stress test for data controllers.
\newline
Aligning with certain scholars, GDPR's information rights on automated decision-making processes can be viewed as a de facto right to explanation. Disregarding this interpretation may jeopardize data subject guarantees, undermining the intended protection of personal data by the new European regulation.
